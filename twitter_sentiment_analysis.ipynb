{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuW4HfTdd0IF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "# Path to the parent folder containing subfolders of tweets\n",
        "parent_folder_path = '/kaggle/input/dataset/public_dataset/train/tweets/'\n",
        "\n",
        "# Get a list of all subfolders in the parent folder\n",
        "subfolders = [f for f in os.listdir(parent_folder_path) if os.path.isdir(os.path.join(parent_folder_path, f))]\n",
        "\n",
        "# Define the sentiment analysis model\n",
        "model = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
        "# Load the sentiment analysis pipeline with CUDA support if available\n",
        "sentiment_task = pipeline(\"sentiment-analysis\", model=model, return_all_scores=True, device=0 if torch.cuda.is_available() else -1)\n",
        "\n",
        "# Loop through each subfolder\n",
        "for subfolder in subfolders:\n",
        "    folder_path = os.path.join(parent_folder_path, subfolder)\n",
        "\n",
        "    # Get a list of all CSV files in the folder\n",
        "    csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
        "\n",
        "    # Initialize an empty list to store dataframes\n",
        "    df_list = []\n",
        "\n",
        "    # Loop through the CSV files and read them into dataframes\n",
        "    for file in csv_files:\n",
        "        try:\n",
        "            file_path = os.path.join(folder_path, file)\n",
        "            df = pd.read_csv(file_path)\n",
        "            df_list.append(df)\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading {file_path}: {e}\")\n",
        "\n",
        "    # Concatenate all dataframes into one\n",
        "    if df_list:  # Check if the list is not empty\n",
        "        merged_df = pd.concat(df_list, ignore_index=True)\n",
        "    else:\n",
        "        print(f\"No valid CSV files found in {folder_path}.\")\n",
        "        continue  # Skip this subfolder if no valid CSV files were found\n",
        "\n",
        "    # Print the length of the merged dataframe\n",
        "    print(f\"Number of rows in the merged dataframe for {subfolder}: {len(merged_df)}\")\n",
        "\n",
        "    # Drop unwanted columns (ensure these columns exist in the merged dataframe)\n",
        "    columns_to_drop = [\n",
        "        'time', 'timezone', 'retweet', 'quote_url', 'link', 'urls',\n",
        "        'user_id', 'language', 'mentions', 'photos', 'video',\n",
        "        'thumbnail', 'place', 'reply_to', 'username', 'name',\n",
        "        'near', 'cashtags', 'hashtags', 'id', 'conversation_id',\n",
        "        'created_at', 'geo', 'user_rt_id', 'user_rt',\n",
        "        'retweet_id', 'retweet_date', 'translate',\n",
        "        'trans_src', 'trans_dest', 'source'\n",
        "    ]\n",
        "\n",
        "    # Safely drop columns that exist in the merged dataframe\n",
        "    merged_df.drop(columns=[col for col in columns_to_drop if col in merged_df.columns], inplace=True)\n",
        "\n",
        "    # Create a new column with the sum of the specified columns\n",
        "    columns_to_sum = ['replies_count', 'retweets_count', 'likes_count']\n",
        "    if all(col in merged_df.columns for col in columns_to_sum):  # Check if columns exist\n",
        "        merged_df['total_sum'] = merged_df[columns_to_sum].sum(axis=1)\n",
        "        merged_df.drop(columns=columns_to_sum, inplace=True)\n",
        "\n",
        "    # Process tweets\n",
        "    if 'tweet' in merged_df.columns:  # Check if 'tweet' column exists\n",
        "        # Function to process each tweet safely\n",
        "        def process_tweet(tweet):\n",
        "            if not isinstance(tweet, str):\n",
        "                return ''\n",
        "            tweet = re.split(r'[@!#\\$]|https?://\\S+', tweet)[0]\n",
        "            words = tweet.split()\n",
        "            return ' '.join(words[:5])\n",
        "\n",
        "        # Apply the function to the 'tweet' column\n",
        "        merged_df['processed_tweet'] = merged_df['tweet'].apply(process_tweet)\n",
        "        merged_df.drop(columns=['tweet'], inplace=True)\n",
        "\n",
        "        # Initialize sentiment score columns\n",
        "        merged_df['negative'] = 0\n",
        "        merged_df['neutral'] = 0\n",
        "        merged_df['positive'] = 0\n",
        "\n",
        "        # Perform sentiment analysis\n",
        "        for i in range(len(merged_df)):\n",
        "            tweet = merged_df[\"processed_tweet\"][i]\n",
        "            if tweet:  # Check if the tweet is not empty\n",
        "                a = sentiment_task(f\"{tweet}\")\n",
        "                merged_df.at[i, 'negative'] = a[0][0]['score']\n",
        "                merged_df.at[i, 'neutral'] = a[0][1]['score']\n",
        "                merged_df.at[i, 'positive'] = a[0][2]['score']\n",
        "\n",
        "        # Save the result DataFrame to a CSV file for the current subfolder\n",
        "        output_csv_path = f'/kaggle/working/{subfolder}_processed.csv'\n",
        "        merged_df.to_csv(output_csv_path, index=False)\n",
        "        print(f\"DataFrame for {subfolder} saved as {subfolder}_processed.csv in the Kaggle working directory.\")\n",
        "    else:\n",
        "        print(f\"'tweet' column not found in {subfolder}.\")\n"
      ]
    }
  ]
}